import os
import io
import asyncio
import httpx
import torch
import timm
import numpy as np
import albumentations as A
import cv2  # ç”¨äº fallback çš„ resizeï¼Œå¦‚æœæ²¡æœ‰ cv2 ä¼šå°è¯•ç”¨ PIL

from typing import List
from pydantic import BaseModel
from albumentations.pytorch import ToTensorV2
from PIL import Image
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from contextlib import asynccontextmanager

# ================= 1. å…¨å±€é…ç½® =================
# è¯·æ ¸å¯¹ä½ çš„æ¨¡å‹è·¯å¾„
MODEL_FOLDER = "./model_all"
NETWORK_TYPE = "resnet50"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ================= 2. é¢„å¤„ç†ç±» (é˜²æŠ¥é”™ç‹¬ç«‹ç‰ˆ) =================
# ä¼˜å…ˆå°è¯•ä» train.py å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å†…ç½®çš„å¤‡ç”¨é€»è¾‘
try:
    from train import ResizeWithPad
    print("âœ… Successfully imported ResizeWithPad from train.py")
except ImportError:
    print("âš ï¸ 'train.py' not found. Using standalone ResizeWithPad fallback.")
    
    class ResizeWithPad:
        """
        å¤‡ç”¨ç¼©æ”¾ç±»ï¼šä¿æŒé•¿å®½æ¯”ç¼©æ”¾ï¼Œå¹¶å¡«å……é»‘è¾¹ (Letterbox)
        """
        def __init__(self, target_shape):
            self.target_h, self.target_w = target_shape

        def __call__(self, image, **kwargs):
            h, w = image.shape[:2]
            scale = min(self.target_h / h, self.target_w / w)
            new_h, new_w = int(h * scale), int(w * scale)
            
            # ä½¿ç”¨ cv2 ç¼©æ”¾
            try:
                resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            except:
                # å¦‚æœæ²¡æœ‰cv2ï¼Œç”¨PILä½œä¸ºæœ€åå…œåº•
                pil_img = Image.fromarray(image)
                resized = np.array(pil_img.resize((new_w, new_h), Image.BILINEAR))

            # è®¡ç®—å¡«å……
            delta_h = self.target_h - new_h
            delta_w = self.target_w - new_w
            top, bottom = delta_h // 2, delta_h - (delta_h // 2)
            left, right = delta_w // 2, delta_w - (delta_w // 2)

            # å¡«å……é»‘è¾¹
            new_image = cv2.copyMakeBorder(
                resized, top, bottom, left, right, 
                cv2.BORDER_CONSTANT, value=[0, 0, 0]
            )
            return new_image

# ================= 3. æ•°æ®æ¨¡å‹å®šä¹‰ =================
class UrlBatchRequest(BaseModel):
    urls: List[str]  # æ¥æ”¶ JSON: {"urls": ["http...", "http..."]}

# ================= 4. ç”Ÿå‘½å‘¨æœŸ (åŠ è½½æ¨¡å‹) =================
ml_models = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    print(f"ğŸš€ Server starting on {DEVICE}...")
    
    # --- åŠ è½½ç±»åˆ« ---
    class_file = os.path.join(MODEL_FOLDER, "class_names.txt")
    if not os.path.exists(class_file):
        raise RuntimeError(f"âŒ Class file missing: {class_file}")
    
    with open(class_file, "r") as f:
        class_names = f.read().splitlines()
    
    # --- åŠ è½½æ¨¡å‹ ---
    print(f"ğŸ”„ Loading {NETWORK_TYPE}...")
    model = timm.create_model(NETWORK_TYPE, pretrained=False, num_classes=len(class_names))
    model.to(DEVICE)
    
    # ä¼˜å…ˆåŠ è½½æœ€ä½³æƒé‡
    weights_path = os.path.join(MODEL_FOLDER, "best_model_params.pt")
    if not os.path.exists(weights_path):
        weights_path = os.path.join(MODEL_FOLDER, "trained_model.pth")
    
    if os.path.exists(weights_path):
        checkpoint = torch.load(weights_path, map_location=DEVICE)
        model.load_state_dict(checkpoint)
        model.eval()
        print(f"âœ… Weights loaded: {os.path.basename(weights_path)}")
    else:
        raise RuntimeError(f"âŒ No model weights found in {MODEL_FOLDER}")

    # --- å®šä¹‰è½¬æ¢ ---
    transform = A.Compose([
        A.Lambda(image=ResizeWithPad((320, 320))), 
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

    ml_models["model"] = model
    ml_models["classes"] = class_names
    ml_models["transform"] = transform
    
    yield
    
    ml_models.clear()
    torch.cuda.empty_cache()
    print("ğŸ›‘ Server shutting down.")

app = FastAPI(lifespan=lifespan, title="Font Classifier API")

# ================= 5. æ ¸å¿ƒé€»è¾‘å‡½æ•° =================
def bytes_to_tensor(content, transform):
    """å°†å›¾ç‰‡å­—èŠ‚æµè½¬ä¸ºé¢„å¤„ç†åçš„Tensor"""
    img = Image.open(io.BytesIO(content)).convert("RGB")
    img_np = np.array(img)
    return transform(image=img_np)["image"]

def batch_inference(tensors, model, class_names):
    """æ‰¹é‡æ¨ç†å¹¶è¿”å›ç»“æœåˆ—è¡¨"""
    if not tensors: return []
    
    batch_input = torch.stack(tensors).to(DEVICE)
    with torch.no_grad():
        logits = model(batch_input)
        probs = torch.softmax(logits, dim=1)
        confs, preds = torch.max(probs, 1)
        
    results = []
    for i in range(len(preds)):
        results.append({
            "prediction": class_names[preds[i].item()],
            "confidence": round(confs[i].item(), 4)
        })
    return results

# ================= 6. API æ¥å£å®šä¹‰ =================

@app.post("/predict_urls")
async def predict_urls(request: UrlBatchRequest):
    """
    ã€æ¨èã€‘é€šè¿‡ JSON æ‰¹é‡è¯†åˆ« URL
    è¾“å…¥: { "urls": ["http://a.com/1.jpg", "http://b.com/2.jpg"] }
    """
    if "model" not in ml_models: raise HTTPException(500, "Model loading...")
    
    urls = [u for u in request.urls if u.strip()]
    if not urls: raise HTTPException(400, "Empty url list")

    print(f"ğŸŒ Downloading {len(urls)} URLs...")

    # å¹¶å‘ä¸‹è½½
    async def fetch(client, url):
        try:
            resp = await client.get(url, follow_redirects=True, timeout=10.0)
            return (resp.content if resp.status_code==200 else None, url, None)
        except Exception as e:
            return (None, url, str(e))

    async with httpx.AsyncClient() as client:
        tasks = [fetch(client, url) for url in urls]
        downloads = await asyncio.gather(*tasks)

    # å¤„ç†ä¸‹è½½ç»“æœ
    valid_tensors = []
    map_indices = [] # è®°å½•æœ‰æ•ˆå›¾ç‰‡åœ¨åŸåˆ—è¡¨ä¸­çš„ä½ç½®
    final_res = [{"url": u, "status": "failed", "error": "unknown"} for u in urls]

    transform = ml_models["transform"]

    for i, (data, url, err) in enumerate(downloads):
        if data:
            try:
                tensor = bytes_to_tensor(data, transform)
                valid_tensors.append(tensor)
                map_indices.append(i)
                final_res[i]["status"] = "success"
                final_res[i]["error"] = None
            except Exception as e:
                final_res[i]["error"] = f"Image Error: {e}"
        else:
            final_res[i]["error"] = f"Download Error: {err}"

    # æ¨ç†
    if valid_tensors:
        preds = batch_inference(valid_tensors, ml_models["model"], ml_models["classes"])
        for idx, pred in zip(map_indices, preds):
            final_res[idx].update(pred)

    return {"total": len(urls), "results": final_res}

@app.post("/predict_files")
async def predict_files(files: List[UploadFile] = File(...)):
    """
    é€šè¿‡ Form-Data æ‰¹é‡ä¸Šä¼ æœ¬åœ°æ–‡ä»¶
    """
    if "model" not in ml_models: raise HTTPException(500, "Model loading...")
    
    valid_tensors = []
    file_names = []
    
    transform = ml_models["transform"]

    print(f"ğŸ“‚ Receiving {len(files)} files...")
    for file in files:
        try:
            content = await file.read()
            if len(content) > 0:
                tensor = bytes_to_tensor(content, transform)
                valid_tensors.append(tensor)
                file_names.append(file.filename)
        except Exception as e:
            print(f"Skipping {file.filename}: {e}")

    if not valid_tensors:
        return {"count": 0, "msg": "No valid images."}

    preds = batch_inference(valid_tensors, ml_models["model"], ml_models["classes"])
    
    # åˆå¹¶æ–‡ä»¶åå’Œç»“æœ
    results = []
    for name, pred in zip(file_names, preds):
        results.append({"filename": name, **pred})

    return {"count": len(results), "results": results}

# ================= 7. å¯åŠ¨å…¥å£ =================
if __name__ == "__main__":
    import uvicorn
    # è¿™é‡Œçš„ reload=False å¾ˆé‡è¦ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹
    uvicorn.run("api:app", host="0.0.0.0", port=6006, reload=False)